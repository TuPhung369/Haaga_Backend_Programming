import React, { useState, useRef } from "react";
import { Button, Card, Container, Spinner, Alert, Form } from "react-bootstrap";
import {
  convertSpeechToText,
  convertTextToSpeech,
  recordAudio,
  playAudio
} from "../services/SpeechService";

/**
 * LanguageAI component for language practice with speech-to-text and text-to-speech
 */
const LanguageAI: React.FC = () => {
  // State for user voice recording and transcription
  const [isRecording, setIsRecording] = useState(false);
  const [userText, setUserText] = useState("");
  const [isTranscribing, setIsTranscribing] = useState(false);

  // State for AI response
  const [aiResponse, setAiResponse] = useState("");
  const [isGeneratingAudio, setIsGeneratingAudio] = useState(false);
  const [audioData, setAudioData] = useState<string | null>(null);

  // Error handling
  const [error, setError] = useState<string | null>(null);

  // References
  const recordingTimeoutRef = useRef<NodeJS.Timeout | null>(null);

  // Language selection (default to Finnish)
  const [language, setLanguage] = useState("fi-FI");

  /**
   * Start recording audio from the user's microphone
   */
  const startRecording = async () => {
    try {
      setError(null);
      setIsRecording(true);

      // Start recording (max 30 seconds)
      const audioBlob = await recordAudio(30000);

      // Transcribe the recorded audio
      await transcribeAudio(audioBlob);
    } catch (error) {
      console.error("Recording error:", error);
      setError(
        "Failed to record audio. Please check your microphone permissions."
      );
    } finally {
      setIsRecording(false);
    }
  };

  /**
   * Stop recording manually before the timeout
   */
  const stopRecording = () => {
    setIsRecording(false);
    // The recording will be handled in the startRecording function's try/catch/finally block
  };

  /**
   * Transcribe an audio blob to text
   */
  const transcribeAudio = async (audioBlob: Blob) => {
    try {
      setIsTranscribing(true);

      // Convert the audio to text
      const transcript = await convertSpeechToText(audioBlob, language);
      setUserText(transcript);

      // Generate AI response to the transcript
      generateAIResponse(transcript);
    } catch (error) {
      console.error("Transcription error:", error);
      setError("Failed to transcribe your speech. Please try again.");
    } finally {
      setIsTranscribing(false);
    }
  };

  /**
   * Generate an AI response to the user's text
   * Note: In a complete implementation, this would call your backend AI service
   */
  const generateAIResponse = async (text: string) => {
    try {
      // Simulate AI processing time
      await new Promise((resolve) => setTimeout(resolve, 1000));

      // Generate a simple response based on the user's text
      // In a real application, this would call your AI service
      const response = `I understood your message: "${text}". This is a simulated AI response. In a complete implementation, this would be generated by your AI service.`;

      setAiResponse(response);

      // Convert the AI response to speech
      generateSpeech(response);
    } catch (error) {
      console.error("AI generation error:", error);
      setError("Failed to generate AI response. Please try again later.");
    }
  };

  /**
   * Convert the AI's text response to speech
   */
  const generateSpeech = async (text: string) => {
    try {
      setIsGeneratingAudio(true);

      // Convert the text to speech
      const audioBase64 = await convertTextToSpeech(text, language);
      setAudioData(audioBase64);

      // Play the audio automatically
      if (audioBase64) {
        playAudio(audioBase64);
      }
    } catch (error) {
      console.error("Text-to-speech error:", error);
      setError("Failed to generate speech from AI response. Please try again.");
    } finally {
      setIsGeneratingAudio(false);
    }
  };

  /**
   * Play the generated audio
   */
  const handlePlayAudio = () => {
    if (audioData) {
      playAudio(audioData);
    }
  };

  return (
    <Container className="py-4">
      <h1 className="mb-4">Language AI Practice</h1>

      {/* Language selection */}
      <Form.Group className="mb-3">
        <Form.Label>Select Language</Form.Label>
        <Form.Select
          value={language}
          onChange={(e) => setLanguage(e.target.value)}
          disabled={isRecording || isTranscribing}
        >
          <option value="fi-FI">Finnish</option>
          <option value="en-US">English</option>
          <option value="sv-SE">Swedish</option>
        </Form.Select>
      </Form.Group>

      {/* Error message if any */}
      {error && (
        <Alert variant="danger" onClose={() => setError(null)} dismissible>
          {error}
        </Alert>
      )}

      {/* Recording controls */}
      <Card className="mb-4">
        <Card.Body>
          <Card.Title>Speak to Practice</Card.Title>
          <Card.Text>
            Click the button below and speak. Your speech will be converted to
            text.
          </Card.Text>

          <div className="d-grid gap-2">
            {!isRecording ? (
              <Button
                variant="primary"
                onClick={startRecording}
                disabled={isTranscribing || isGeneratingAudio}
              >
                Start Speaking
              </Button>
            ) : (
              <Button variant="danger" onClick={stopRecording}>
                Stop Speaking{" "}
                {isRecording && <Spinner animation="border" size="sm" />}
              </Button>
            )}
          </div>

          {/* User's transcribed text */}
          {isTranscribing && (
            <div className="text-center mt-3">
              <Spinner animation="border" />
              <p>Transcribing your speech...</p>
            </div>
          )}

          {userText && (
            <div className="mt-3">
              <h5>Your Speech:</h5>
              <div className="p-3 bg-light rounded">{userText}</div>
            </div>
          )}
        </Card.Body>
      </Card>

      {/* AI Response */}
      {aiResponse && (
        <Card className="mb-4">
          <Card.Body>
            <Card.Title>AI Response</Card.Title>

            <div className="p-3 bg-light rounded mb-3">{aiResponse}</div>

            {/* Audio controls */}
            <div className="d-flex justify-content-center">
              {isGeneratingAudio ? (
                <div className="text-center">
                  <Spinner animation="border" />
                  <p>Generating audio...</p>
                </div>
              ) : (
                audioData && (
                  <Button variant="success" onClick={handlePlayAudio}>
                    Play Response
                  </Button>
                )
              )}
            </div>
          </Card.Body>
        </Card>
      )}
    </Container>
  );
};

export default LanguageAI;
